from typing import Dict, List, Optional, Any
import pandas as pd
from utils.normalize import norm_key, values_equal, norm_col

def _read_table(path: str, header_row_1based: int) -> pd.DataFrame:
    header_idx = header_row_1based - 1
    df = pd.read_excel(path, header=header_idx, engine='calamine')
    df = df.loc[:,~df.columns.to_series().apply(lambda x: str(x).startswith('Unnamed'))]
    df.columns = [norm_col(col) for col in df.columns]
    return df

def run_reference_check(
        main_path: str,
        ref_path: str,
        key_column: str,
        compare_columns: List[str],
        main_header_row: int = 1,
        ref_header_row: int = 1,
        main_run_date: Optional[str] = None,
        ref_run_date: Optional[str] = None,
        main_filename: Optional[str] = None,
        ref_filename: Optional[str] = None
) -> Dict[str, Any]:
    # Read both files in parallel for faster processing
    from concurrent.futures import ThreadPoolExecutor
    
    with ThreadPoolExecutor(max_workers=2) as executor:
        fut_main = executor.submit(_read_table, main_path, main_header_row)
        fut_ref = executor.submit(_read_table, ref_path, ref_header_row)
        
        df_main = fut_main.result()
        df_ref = fut_ref.result()

    key_column = norm_col(key_column)
    compare_columns = [norm_col(col) for col in compare_columns if norm_col(col)]
    compare_columns = [col for col in compare_columns if col != key_column]

    if key_column not in df_main.columns:
        raise ValueError(f"Key column '{key_column}' not found in main table.")
    if key_column not in df_ref.columns:
        raise ValueError(f"Key column '{key_column}' not found in reference table.")
    
    missing_main = [c for c in compare_columns if c not in df_main.columns]
    missing_ref = [c for c in compare_columns if c not in df_ref.columns]
    existing_compare = [c for c in compare_columns if c in df_main.columns and c in df_ref.columns]

    if not existing_compare:
        raise ValueError("No valid compare columns found in both tables.")
    
    # Normalize keys
    df_main[key_column] = df_main[key_column].apply(norm_key)
    df_ref[key_column] = df_ref[key_column].apply(norm_key)

    if (df_main[key_column] == "").any():
        raise ValueError("Empty keys found in main table after normalization.")
    if (df_ref[key_column] == "").any():
        raise ValueError("Empty keys found in reference table after normalization.")
    
    if df_main[key_column].duplicated().any():
        dup = df_main[df_main[key_column].duplicated(keep=False)][key_column].unique()
        raise ValueError(f"Duplicate keys found in main table after normalization: {dup}")
    if df_ref[key_column].duplicated().any():
        dup = df_ref[df_ref[key_column].duplicated(keep=False)][key_column].unique()
        raise ValueError(f"Duplicate keys found in reference table after normalization: {dup}")
    
    # Vectorized approach: merge to identify added/deleted/common
    cols_to_compare = [key_column] + existing_compare
    df_main_subset = df_main[cols_to_compare].copy()
    df_ref_subset = df_ref[cols_to_compare].copy()
    
    # Merge with indicator to track source
    merged = df_main_subset.merge(
        df_ref_subset,
        on=key_column,
        how='outer',
        suffixes=('_main', '_ref'),
        indicator=True
    )
    
    # Identify added, deleted, and common keys
    added_mask = merged['_merge'] == 'left_only'
    deleted_mask = merged['_merge'] == 'right_only'
    common_mask = merged['_merge'] == 'both'
    
    added_keys = merged[added_mask][key_column].tolist()
    deleted_keys = merged[deleted_mask][key_column].tolist()
    
    anomalies = []
    
    # Added rows
    for k in added_keys:
        anomalies.append({
            "change_type": "Added",
            "key": k,
            "column_name": "",
            "old_value": "",
            "new_value": "(new row)",
        })

    # Deleted rows
    for k in deleted_keys:
        anomalies.append({
            "change_type": "Deleted",
            "key": k,
            "column_name": "",
            "old_value": "(deleted row)",
            "new_value": "",
        })

    # Vectorized comparison for common rows
    common_df = merged[common_mask].copy()
    
    if len(common_df) > 0:
        # For each compare column, check if values differ
        for col in existing_compare:
            col_main = f"{col}_main"
            col_ref = f"{col}_ref"
            
            # Normalize values for comparison (fillna to handle NaN)
            main_vals = common_df[col_main].fillna('').astype(str).str.strip()
            ref_vals = common_df[col_ref].fillna('').astype(str).str.strip()
            
            # Find rows where values differ
            diff_mask = main_vals != ref_vals
            
            if diff_mask.any():
                # Extract the changed rows
                changed_rows = common_df[diff_mask]
                
                for _, row in changed_rows.iterrows():
                    old_val = row[col_ref]
                    new_val = row[col_main]
                    
                    anomalies.append({
                        "change_type": "Modified",
                        "key": row[key_column],
                        "column_name": col,
                        "old_value": old_val if pd.notna(old_val) else "",
                        "new_value": new_val if pd.notna(new_val) else "",
                    })
    
    # Count modified rows and cells
    modified_df = pd.DataFrame(anomalies)
    modified_records = modified_df[modified_df['change_type'] == 'Modified']
    modified_rows = modified_records['key'].nunique() if len(modified_records) > 0 else 0
    modified_cells = len(modified_records)
    
    anomalies_df = pd.DataFrame(anomalies, columns=["change_type", "key", "column_name", "old_value", "new_value"])

    summary = {
        "main_file": main_filename if main_filename else main_path,
        "ref_file": ref_filename if ref_filename else ref_path,
        "key_column": key_column,
        "compared_columns": existing_compare,
        "added_rows": len(added_keys),
        "deleted_rows": len(deleted_keys),
        "modified_rows": modified_rows,
    }

    return {
        "summary": summary,
        "anomalies_df": anomalies_df,
    }
